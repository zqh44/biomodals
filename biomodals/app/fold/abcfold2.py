"""Run ABCFold on Modal GPU instances.

Ephemeral usage example:

    ```bash
    modal run scripts/fold/abcfold2.py --input-yaml path/to/example.yaml
    ```

Deployment usage example:
    https://modal.com/docs/guide/managing-deployments

    ```bash
    modal deploy scripts/fold/abcfold2.py --name ABCFold2
    ```

    See `clients/fold/abcfold2.py` for example client code to call the deployed app.
"""
# Ignore ruff warnings about import location and unsafe subprocess usage
# ruff: noqa: PLC0415, S603

import os
from datetime import UTC
from pathlib import Path

from modal import App, Image, Volume

##########################################
# Modal configs
# T4: 16GB, L4: 24GB, A10G: 24GB, L40S: 48GB, A100-40G, A100-80G, H100: 80GB
# https://modal.com/docs/guide/gpu
GPU = os.environ.get("GPU", "A10G")
TIMEOUT = int(os.environ.get("TIMEOUT", "1800"))  # seconds

# Volume for model cache
CHAI_VOLUME_NAME = "chai-models"
CHAI_VOLUME = Volume.from_name(CHAI_VOLUME_NAME, create_if_missing=True)
CHAI_MODEL_DIR = "/chai-models"

BOLTZ_VOLUME_NAME = "boltz-models"
BOLTZ_VOLUME = Volume.from_name(BOLTZ_VOLUME_NAME, create_if_missing=True)
BOLTZ_MODEL_DIR = "/boltz-models"

# Volume for outputs
OUTPUTS_VOLUME_NAME = "abcfold2-outputs"
OUTPUTS_VOLUME = Volume.from_name(OUTPUTS_VOLUME_NAME, create_if_missing=True)
OUTPUTS_DIR = "/abcfold2-outputs"

# Repositories and commit hashes
ABCFOLD_DIR = "/opt/ABCFold"
ABCFOLD_REPO = "https://github.com/y1zhou/ABCFold"
ABCFOLD_COMMIT = "75630348b861258746a1f2832c1537ef14c45671"

CHAI_DIR = "/opt/chai-lab"
CHAI_REPO = "https://github.com/y1zhou/chai-lab"
CHAI_COMMIT = "0ac68311911bfcd28b118fc289437bf3eff8ac97"

BOLTZ_DIR = "/opt/boltz"
BOLTZ_REPO = "https://github.com/jwohlwend/boltz"
BOLTZ_COMMIT = "cb04aeccdd480fd4db707f0bbafde538397fa2ac"
BOLTZ_MODEL_HASH = "6fdef46d763fee7fbb83ca5501ccceff43b85607"  # HF revision
##########################################

download_image = (
    Image.debian_slim()
    .pip_install("huggingface_hub[hf_transfer]==0.26.3")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})  # speed up downloads
)

runtime_image = (
    Image.debian_slim()
    .apt_install("git", "build-essential", "kalign")  # kalign for Chai templates
    .env(
        {
            # "UV_COMPILE_BYTECODE": "1",  # slower image build, faster runtime
            # https://modal.com/docs/guide/cuda
            "UV_TORCH_BACKEND": "cu128",  # find best torch and CUDA versions
            "CHAI_DOWNLOADS_DIR": str(CHAI_MODEL_DIR),  # store chai model weights
            "BOLTZ_CACHE_DIR": str(BOLTZ_MODEL_DIR),  # store boltz model weights
        }
    )
    .run_commands(
        " && ".join(
            (
                # Clone Boltz and Chai
                f"git clone {BOLTZ_REPO} {BOLTZ_DIR}",
                f"cd {BOLTZ_DIR}",
                f"git checkout {BOLTZ_COMMIT}",
                f"git clone {CHAI_REPO} {CHAI_DIR}",
                f"cd {CHAI_DIR}",
                f"git checkout {CHAI_COMMIT}",
                # Setup ABCFold2 environment
                f"git clone {ABCFOLD_REPO} {ABCFOLD_DIR}",
                f"cd {ABCFOLD_DIR}",
                f"git checkout {ABCFOLD_COMMIT}",
                "uv venv --python 3.12",
                f"uv pip install {BOLTZ_DIR}[cuda] {CHAI_DIR}",
                "uv pip install .",
            ),
        )
    )
    .env({"PATH": f"{ABCFOLD_DIR}/.venv/bin:$PATH"})
    .workdir(ABCFOLD_DIR)
)

app = App("ABCFold2", image=runtime_image)


@app.function(
    volumes={BOLTZ_MODEL_DIR: BOLTZ_VOLUME}, timeout=TIMEOUT, image=download_image
)
def download_boltz_models(force: bool = False) -> None:
    """Download Boltz models into the mounted volume.

    From: https://modal.com/docs/examples/boltz_predict.
    """
    import tarfile

    from huggingface_hub import snapshot_download

    snapshot_download(
        repo_id="boltz-community/boltz-2",
        revision=BOLTZ_MODEL_HASH,
        local_dir=BOLTZ_MODEL_DIR,
        force_download=force,
    )
    tar_mols = Path(BOLTZ_MODEL_DIR) / "mols.tar"
    if not (Path(BOLTZ_MODEL_DIR) / "mols").exists():
        with tarfile.open(str(tar_mols), "r") as tar:
            tar.extractall(BOLTZ_MODEL_DIR)  # noqa: S202

    BOLTZ_VOLUME.commit()


async def download_file(session, url: str, local_path: Path):
    """Download a file asynchronously using aiohttp."""
    async with session.get(url) as response:
        response.raise_for_status()
        local_path.parent.mkdir(parents=True, exist_ok=True)
        with open(local_path, "wb") as f:
            while chunk := await response.content.read(8192):
                f.write(chunk)


@app.function(
    volumes={CHAI_MODEL_DIR: CHAI_VOLUME}, timeout=TIMEOUT, image=download_image
)
async def download_chai_models(force=False):
    """From https://modal.com/docs/examples/chai1."""
    import asyncio

    import aiohttp

    base_url = "https://chaiassets.com/chai1-inference-depencencies/"  # sic
    inference_dependencies = [
        "conformers_v1.apkl",
        "models_v2/trunk.pt",
        "models_v2/token_embedder.pt",
        "models_v2/feature_embedding.pt",
        "models_v2/diffusion_module.pt",
        "models_v2/confidence_head.pt",
        "models_v2/bond_loss_input_proj.pt",
        "esm2/traced_sdpa_esm2_t36_3B_UR50D_fp16.pt",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }

    # launch downloads concurrently
    chai_model_dir = Path(CHAI_MODEL_DIR)
    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = []
        for dep in inference_dependencies:
            local_path = chai_model_dir / dep
            if force or not local_path.exists():
                url = base_url + dep
                print(f"ðŸ§¬ downloading {dep} to {local_path}")
                tasks.append(download_file(session, url, local_path))

        # run all of the downloads and await their completion
        await asyncio.gather(*tasks)

    # Special treatment for ESM
    esm2_path = chai_model_dir / "esm2" / "traced_sdpa_esm2_t36_3B_UR50D_fp16.pt"
    esm_path = chai_model_dir / "esm" / "traced_sdpa_esm2_t36_3B_UR50D_fp16.pt"
    if esm2_path.exists() and not esm_path.exists():
        esm_path.parent.mkdir(parents=True, exist_ok=True)
        esm_path.symlink_to(esm2_path)

    CHAI_VOLUME.commit()  # ensures models are visible on remote filesystem before exiting, otherwise takes a few seconds, racing with inference


def load_params_from_run_yaml(yaml_path: Path) -> dict:
    """Load run parameters from ABCFold2 YAML config."""
    from abcfold.schema import load_abcfold_config

    conf = load_abcfold_config(yaml_path)
    return {
        "seeds": conf.seeds,
        "num_trunk_recycles": conf.num_trunk_recycles,
        "num_diffn_timesteps": conf.num_diffn_timesteps,
        "num_diffn_samples": conf.num_diffn_samples,
        "num_trunk_samples": conf.num_trunk_samples,
        "boltz_additional_cli_args": conf.boltz_additional_cli_args,
    }


@app.function(
    image=runtime_image,
    timeout=TIMEOUT,
    volumes={OUTPUTS_DIR: OUTPUTS_VOLUME, BOLTZ_MODEL_DIR: BOLTZ_VOLUME},
)
def prepare_abcfold2(
    yaml_str: bytes, run_id: str
) -> dict[str, str | list[int] | int | list[str] | None]:
    """Prepare inputs to Boltz and Chai using ABCFold2 config."""
    import tempfile

    from abcfold.cli.prepare import prepare_boltz, prepare_chai, search_msa

    out_dir_full: Path = Path(OUTPUTS_DIR) / run_id[:2] / run_id
    out_dir_full.mkdir(parents=True, exist_ok=True)
    yaml_path = Path(out_dir_full) / f"{run_id}.yaml"

    if yaml_path.exists():
        conf = load_params_from_run_yaml(yaml_path)
        conf["workdir"] = str(out_dir_full)
        return conf

    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_yaml_path = Path(tmpdir) / f"{run_id}.yaml"
        tmp_yaml_path.write_bytes(yaml_str)

        # Run MSA and template search
        if not yaml_path.exists():
            search_msa(
                conf_file=tmp_yaml_path,
                out_dir=out_dir_full,
                force=True,
                template_cache_dir=Path(OUTPUTS_DIR) / ".cache" / "rcsb",
            )
            OUTPUTS_VOLUME.commit()

    # Generate inputs for Boltz and Chai
    _ = prepare_boltz(conf_file=yaml_path, out_dir=out_dir_full)
    _ = prepare_chai(
        conf_file=yaml_path,
        out_dir=out_dir_full,
        ccd_lib_dir=Path(BOLTZ_MODEL_DIR) / "mols",
    )

    # Pull run parameters from YAML
    conf = load_params_from_run_yaml(yaml_path)
    conf["workdir"] = str(out_dir_full)
    return conf


def package_outputs(output_dir: str) -> bytes:
    """Package output directory into a tar.gz archive and return as bytes."""
    import io
    import tarfile
    from pathlib import Path

    tar_buffer = io.BytesIO()
    out_path = Path(output_dir)
    with tarfile.open(fileobj=tar_buffer, mode="w:gz", compresslevel=6) as tar:
        tar.add(out_path, arcname=out_path.name)

    return tar_buffer.getvalue()


@app.function(
    cpu=1.0,
    image=runtime_image,
    timeout=TIMEOUT,
    volumes={OUTPUTS_DIR: OUTPUTS_VOLUME, BOLTZ_MODEL_DIR: BOLTZ_VOLUME},
)
def collect_abcfold2_boltz_data(
    run_conf: dict[str, str | list[int] | int | list[str] | None],
):
    """Manage Boltz runs and return all Boltz results."""
    from pathlib import Path

    work_path = Path(run_conf["workdir"]).expanduser().resolve()
    run_id = work_path.stem
    work_path = work_path / f"boltz_{run_id}"
    boltz_conf_path = work_path / f"{run_id}.yaml"
    if not boltz_conf_path.exists():
        raise FileNotFoundError(f"Boltz config file not found: {boltz_conf_path}")

    random_seeds = run_conf.get("seeds", [])
    seeds_to_run = []
    for seed in random_seeds:
        boltz_run_dir = work_path / f"boltz_results_{run_id}_seed-{seed}"
        if not boltz_run_dir.exists():
            seeds_to_run.append(seed)

    if seeds_to_run:
        run_abcfold2_boltz.map(seeds_to_run, kwargs=run_conf)

    return package_outputs(str(work_path))


@app.function(
    gpu=GPU,
    image=runtime_image,
    timeout=TIMEOUT,
    volumes={OUTPUTS_DIR: OUTPUTS_VOLUME, BOLTZ_MODEL_DIR: BOLTZ_VOLUME},
    max_containers=10,
)
def run_abcfold2_boltz(
    seed: int,
    workdir: str | Path,
    num_trunk_recycles: int,  # recycling_steps
    num_diffn_timesteps: int,  # sampling_steps
    num_diffn_samples: int,  # diffusion_samples
    boltz_additional_cli_args: list[str] | None,
    **kwargs,  # ignore extra items from run config
) -> str:
    """Run Boltz with the given ABCFold2 configuration."""
    from abcfold.boltz.run_boltz_abcfold import run_boltz

    work_path = Path(workdir).expanduser().resolve()
    run_id = work_path.stem
    work_path = work_path / f"boltz_{run_id}"
    boltz_conf_path = work_path / f"{run_id}.yaml"
    if not boltz_conf_path.exists():
        raise FileNotFoundError(f"Boltz config file not found: {boltz_conf_path}")

    boltz_run_dir = run_boltz(
        output_dir=work_path,
        boltz_yaml_file=boltz_conf_path,
        run_id=run_id,
        seed=seed,
        num_trunk_recycles=num_trunk_recycles,
        num_diffn_timesteps=num_diffn_timesteps,
        num_diffn_samples=num_diffn_samples,
        boltz_additional_cli_args=boltz_additional_cli_args,
    )
    OUTPUTS_VOLUME.commit()
    return str(boltz_run_dir)


@app.function(
    cpu=1.0,
    image=runtime_image,
    timeout=TIMEOUT,
    volumes={OUTPUTS_DIR: OUTPUTS_VOLUME, CHAI_MODEL_DIR: CHAI_VOLUME},
)
def collect_abcfold2_chai_data(
    run_conf: dict[str, str | list[int] | int | list[str] | None],
):
    """Manage Chai runs and return all Chai results."""
    from pathlib import Path

    work_path = Path(run_conf["workdir"]).expanduser().resolve()
    run_id = work_path.stem
    work_path = work_path / f"chai_{run_id}"
    chai_conf_path = work_path / f"{run_id}.yaml"
    if not chai_conf_path.exists():
        raise FileNotFoundError(f"Chai config file not found: {chai_conf_path}")

    random_seeds = run_conf.get("seeds", [])
    seeds_to_run = []
    for seed in random_seeds:
        chai_run_dir = work_path / f"chai_{run_id}_seed-{seed}"
        if not chai_run_dir.exists():
            seeds_to_run.append(seed)

    if seeds_to_run:
        run_abcfold2_chai.map(seeds_to_run, kwargs=run_conf)

    return package_outputs(str(work_path))


@app.function(
    gpu=GPU,
    image=runtime_image,
    timeout=TIMEOUT,
    volumes={OUTPUTS_DIR: OUTPUTS_VOLUME, CHAI_MODEL_DIR: CHAI_VOLUME},
    max_containers=10,
)
def run_abcfold2_chai(
    seed: int,
    workdir: str | Path,
    num_trunk_recycles: int,
    num_diffn_timesteps: int,
    num_diffn_samples: int,
    num_trunk_samples: int,
    **kwargs,  # ignore extra items from run config
) -> str:
    """Run Chai with the given ABCFold2 configuration."""
    from abcfold.chai1.run_chai1_abcfold import run_chai

    work_path = Path(workdir).expanduser().resolve()
    run_id = work_path.stem
    chai_work_path = work_path / f"chai_{run_id}"
    chai_conf_path = chai_work_path / f"{run_id}.yaml"
    if not chai_conf_path.exists():
        raise FileNotFoundError(f"Chai config file not found: {chai_conf_path}")

    chai_run_dir = run_chai(
        output_dir=chai_work_path,
        chai_yaml_file=chai_conf_path,
        seed=seed,
        template_hits_path=work_path / "msa" / "all_chain_templates.m8",
        template_cif_dir=work_path / "msa" / "templates",
        num_trunk_recycles=num_trunk_recycles,
        num_diffn_timesteps=num_diffn_timesteps,
        num_diffn_samples=num_diffn_samples,
        num_trunk_samples=num_trunk_samples,
    )
    OUTPUTS_VOLUME.commit()
    return str(chai_run_dir)


def run_abcfold2(
    input_yaml: str,
    run_name: str | None = None,
    download_models: bool = False,
    force_redownload: bool = False,
    run_boltz: bool = True,
    run_chai: bool = True,
) -> None:
    """Run ABCFold2 on modal and fetch results to $CWD.

    Args:
        input_yaml: Path to YAML design specification file
        run_name: Optional run name (defaults to timestamp-{input file hash})
        download_models: Whether to download model weights before running
        force_redownload: Whether to force re-download of model weights
        run_boltz: Whether to run Boltz inference
        run_chai: Whether to run Chai inference
    """
    import hashlib
    from datetime import datetime

    if download_models:
        print("ðŸ§¬ Checking Boltz inference dependencies...")
        download_boltz_models.remote(force=force_redownload)

        print("ðŸ§¬ Checking Chai inference dependencies...")
        download_chai_models.remote(force=force_redownload)

    # Load input and find its hash
    yaml_path = Path(input_yaml).expanduser().resolve()
    yaml_str = yaml_path.read_bytes()

    run_id = hashlib.sha256(yaml_str).hexdigest()  # content-based id
    today: str = datetime.now(UTC).strftime("%Y%m%d%H%M")
    if run_name is None:
        run_name = run_id[:8]  # short id

    local_out_dir = Path.cwd() / f"{today}-{run_name}"
    if local_out_dir.exists():
        raise FileExistsError(f"Output directory already exists: {local_out_dir}")

    print(f"ðŸ§¬ Starting ABCFold2 run {run_id}...")
    run_conf = prepare_abcfold2.remote(yaml_str=yaml_str, run_id=run_id)

    # Run Boltz for each seed
    if run_boltz:
        out_path = local_out_dir / f"boltz_{run_id}.tar.gz"
        print(f"ðŸ§¬ Running Boltz and collecting results to {out_path}")
        boltz_data = collect_abcfold2_boltz_data.remote(run_conf=run_conf)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_bytes(boltz_data)

    # Run Chai for each seed
    if run_chai:
        out_path = local_out_dir / f"chai_{run_id}.tar.gz"
        print(f"ðŸ§¬ Running Chai and collecting results to {out_path}")
        chai_data = collect_abcfold2_chai_data.remote(run_conf=run_conf)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_bytes(chai_data)

    print(f"ðŸ§¬ ABCFold2 run complete! Results saved to {local_out_dir}")


main = app.local_entrypoint()(run_abcfold2)
